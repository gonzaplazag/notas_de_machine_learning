{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# La posibilidad de aprender a partir de datos\n",
    "\n",
    "El objetivo del aprendizaje es conocer una función objetivo $f$, que asocia valores de input con valores de output determinados. Esta función $f$ es desconocida y no es posible de conocer directamente.\n",
    "\n",
    "El acercamiento a esta función se realiza mediante el conocimiento de un conjunto de datos parcial, el dataset de entrenamiento. ¿Puede un dataset parcial darnos a conocer suficientes cosas como para poder realizar dicho acercamiento?.\n",
    "\n",
    "## Acercamiento probabilístico al problema\n",
    "\n",
    "La posibilidad de aprender de una población a partir de un conjunto de datos parcial es un problema tratado por la estadística. Esta nos ayuda a establecer ciertas condiciones bajos las cuales dicho proceso de aprendizaje es posible.\n",
    "\n",
    "El modelo probabilístico básico que permite justificar la posibilidad del aprendizaje se menciona a continuación.\n",
    "\n",
    "Tenemos un espacio de entrada $X$ del cual se quiere aprender y para eso se cuenta con un dataset de entrenamiento $D$. Sabemos que, para cada valor de entrada, existe un valor de $y = f(x)$ de respuesta, desconocido para nosotros, pero existente. \n",
    "\n",
    "A partir de un proceso de aprendizaje se genera una función $g$ que aproxima (mejor o peor) a $f$. Esta función $g$ al ser evaluada en un conjunto parcial de datos de $X$, llamado $D_t$ (que pueden ser el mismo dataset $D$ u otros datos utilizados específicamente para este rol de evaluación posterior), genera respuestas $g(x), que pueden ser correctas o incorrectas respecto a los valores reales f(x). \n",
    "\n",
    "La proporción de valores bien predichos en $D_t$ se puede establecer directamente, no así la situación en todo el dataset $X$. Sin embargo, se puede demostrar que en el caso de ser $D_t$ una muestra aleatoria con reposición de $X$, entonces se cumple la siguiente desigualdad: $$P(|v-\\mu| > \\epsilon) \\leq 2e^{-2\\epsilon^2N}$$ conocida como **desigualdad de Hoeffding**, con $\\mu$ la verdadera proporción de bien predichos en $X$ y $v$ la proporción de bien predichos en el dataset $D_t$. La desigualdad nos asegura entonces que en estas circunstancias:\n",
    "\n",
    "1. Es posible acotar la probabilidad de que el error de predicción entre $v$ y $\\mu$ sea más grande que un valor específico (cualquiera sea este valor específico), sólo aumentando el tamaño de la muestra.\n",
    "\n",
    "2. Este ejercicio de tomar datos parciales y evualuar sobre estos la capacidad predictiva de mi función $g$ es un ejercicio válido.\n",
    "\n",
    "3. Las conclusiones anteriores se sostienen cuando el conjunto de testeo $D_t$ es una muestra aleatoria del conjunto $X$. En otros casos, no es posible sostenar dichas afirmaciones.\n",
    "\n",
    "Se denomina **error en la muestra** al valor $v$, o sea a la proporción de mal clasificados en la muestra de datos conocida. Se denomina **error fuera de la muestra** a la proporción $\\mu$ de mal clasificados por mi función $h$ en los datos totales $X$. La afirmación anterior con esta nueva situación se resume diciendo que es posible acotar la diferencia tanto como se quiera entre el error en la muestra y el fuera de la muestra, modificando el tamaño de esta. Con esta notación, la desigualdad queda como $$P(|E_in(h)-E_out(h)| > \\epsilon) \\leq 2e^{-2\\epsilon^2N}$$\n",
    "\n",
    "Este enfoque entonces asegura que, dada la hipótesis seleccionada $h$ y su asociada función de aproximación $g$, es posible establecer una medida probabilistamente confiable de lo bien que actua dicha hipótesis para clasificar casos en general.\n",
    "\n",
    "### Incorporación del problema del set de hipótesis al argumento\n",
    "\n",
    "El argumento anterior depende de la elección de $h$, como explicita la segunda notación. La elección de $h$ establece los valores predichos (conocidos en la muestra como desconocidos en la población), y por lo tanto ambos errores de predicción $E_in(h)$ y $E_out(h)$. \n",
    "\n",
    "En la realidad no se prueba una sola hipótesis, sino que se prueba un conjunto de hipótesis del set de hipótesis $H$. Es muy importante saber que la medida muestral del error es una aproximación válida a la medida poblacional, pero lo útil es elegir la hipótesis que de la menor medida posible.\n",
    "\n",
    "Suponiendo que en vez de tomar una hipótesis individual y querer establecer una métrica de la probabilidad de error, lo que hacemos es tomar muchas hipótesis $h$, quedarnos con la menor $g$, y queremos establecer la medida de la probabilida de error, tenemos que la desigualdad de Hoeffding toma la forma $$P(|E_in(g)-E_out(g)| > \\epsilon) \\leq 2Me^{-2\\epsilon^2N}$$\n",
    "\n",
    "donde $g$ es la hipótesis \"optima\", y M es la cantidad de hipótesis estudiadas (que por simplicidad aquí se supone finita).\n",
    "\n",
    "En esta nueva situación, es posible también establecer la cota, aunque es una cota no tan ajustada. Esto mantiene los resultados anteriormente vistos para este caso, pero hace necesario cantidades mayores de información para poder asegurar buenos resultados. Además, sólo aplica para casos de una cantidad finita de hipotesis, cosa que no es razonable. \n",
    "\n",
    "## Introducción al problema sesgo-varianza\n",
    "\n",
    "De la explicación anterior surge que la posibilidad del aprendizaje es un problema que cuenta con al menos dos interrogantes:\n",
    "\n",
    "1. Dado que queremos aproximar $f$, es posible establecer una métrica que nos dé cuenta de lo bien que estamos aproximando. Este problema se ataca mediante la desigualdad de Hoeffding.\n",
    "\n",
    "2. Podríamos tener una métrica de si estamos aproximando bien o mal, pero al final del día lo relevante es encontrar métodos para aproximar bien. Como es esto posible?\n",
    "\n",
    "Pareciera que sin una buena guía de lo bien que se está aproximando, simplemente no es posible establecer hipótesis mejores o peores. Ahora bien, la métrica en si misma no es el objetivo, que es encontrar una buena aproximación.\n",
    "\n",
    "Pareciera que la bondad de la aproximación depende fuertemente de la cantidad de hipótesis que se evaluen. Mientras mas grande, **complejo**, sea el conjunto de hipótesis $H$, más chances habrían de que dentro de este se encuentre una mejor hipótesis. \n",
    "\n",
    "Sin embargo, esto genera la siguiente situación. Al aumentar la cantidad e hipótesis a evaluar tenemos más chance de tener una buena hipótesis, o sea de disminuir el **sesgo** del procedimiento. Por otro lado, al realizar esto, la cota que nos da una medida de lo bueno de nuestra medida se hace más débil, o sea, tiene a **aumentar la varianza** de la respuesta buscada. Esto es un problema.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}